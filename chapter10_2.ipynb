{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 超解像_Skip Connections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### chapter10 と同じデータを使い、モデルをもう一つ複雑なモデルにします"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### this model can not work well by now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import math\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.python import keras\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.models import Model,Sequential\n",
    "from tensorflow.python.keras.layers import Conv2D,Dense,Input,MaxPooling2D, UpSampling2D,Lambda\n",
    "from tensorflow.python.keras.preprocessing.image import load_img,img_to_array,array_to_img,ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_resolution(x,scale=3.0):\n",
    "    size = (x.shape[0],x.shape[1])\n",
    "    small_size = (int(size[0]/scale), int(size[1]/scale))\n",
    "    img = array_to_img(x)\n",
    "    small_img = img.resize(small_size,3)\n",
    "    return img_to_array(small_img.resize(img.size,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "import scipy\n",
    "def data_generator(data_dir,mode,scale=2.0,target_size=(200,200),batch_size=32,shuffle = True):\n",
    "    for imgs in ImageDataGenerator().flow_from_directory(\n",
    "        directory = data_dir,\n",
    "        classes = [mode],\n",
    "        class_mode = None,\n",
    "        color_mode = 'rgb',\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        shuffle = shuffle\n",
    "    ):\n",
    "        x = np.array([drop_resolution(img,scale) for img in imgs])\n",
    "        yield x/255.,imgs/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = 'img_c10'\n",
    "N_TRAIN_DATA = 1000\n",
    "N_TEST_DATA = 100\n",
    "BATCH_SIZE = 20\n",
    "train_data_generator = data_generator(DATA_DIR, 'train', batch_size = BATCH_SIZE)\n",
    "test_x,test_y = next(data_generator(\n",
    "        DATA_DIR,\n",
    "        'test',\n",
    "        #target_size = (10,10),\n",
    "        batch_size = N_TEST_DATA,\n",
    "        shuffle = False\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, None, None, 1 448         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, None, None, 1 2320        conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, None, None, 1 2320        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, None, None, 1 2320        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, None, None, 1 2320        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, None, None, 1 2320        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, None, None, 1 2320        conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, None, None, 1 2320        conv2d_transpose[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, None, None, 1 0           conv2d_transpose_1[0][0]         \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, None, None, 1 2320        add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, None, None, 1 2320        conv2d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, None, None, 1 0           conv2d_transpose_3[0][0]         \n",
      "                                                                 conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, None, None, 1 2320        add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTrans (None, None, None, 3 435         conv2d_transpose_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, None, None, 3 0           conv2d_transpose_5[0][0]         \n",
      "                                                                 input_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 24,083\n",
      "Trainable params: 24,083\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.layers import Add\n",
    "from tensorflow.python.keras.layers import Conv2DTranspose\n",
    "inputs = Input((None,None,3), dtype = 'float')\n",
    "#Encoder\n",
    "conv1 = Conv2D(64,3,padding= 'same')(inputs)\n",
    "conv1 = Conv2D(64,3,padding ='same')(conv1)\n",
    "conv2 = Conv2D(64,3,strides = 2,padding = 'same')(conv1)\n",
    "conv2 = Conv2D(64,3,padding = 'same')(conv2)\n",
    "conv3 = Conv2D(64,3,strides = 2, padding = 'same')(conv2)\n",
    "conv3 = Conv2D(64,3,padding='same')(conv3)\n",
    "\n",
    "#Decoder\n",
    "deconv3 = Conv2DTranspose(64,3,padding='same')(conv3)\n",
    "deconv3 = Conv2DTranspose(64,3,strides = 2, padding= 'same')(deconv3)\n",
    "\n",
    "#use add() layer to realize the skip connection function\n",
    "merge2 = Add()([deconv3,conv2])\n",
    "deconv2 = Conv2DTranspose(64,3,padding='same')(merge2)\n",
    "deconv2 = Conv2DTranspose(64,3,strides =2,padding='same')(deconv2)\n",
    "merge1 = Add()([deconv2,conv1])\n",
    "deconv1 = Conv2DTranspose(64,3,padding='same')(merge1)\n",
    "deconv1 = Conv2DTranspose(3,3,padding='same')(deconv1)\n",
    "output = Add()([deconv1,inputs])\n",
    "model = Model(inputs,output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psnr(y_true,y_pred):\n",
    "    return -10*K.log(\n",
    "        K.mean(K.flatten((y_true - y_pred))**2)\n",
    "    )/np.log(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss = 'mean_squared_error',\n",
    "    optimizer = 'adam',\n",
    "    metrics = [psnr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allocator_type ='BFC'\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "Found 1000 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_data_generator,\n",
    "    validation_data = (test_x,test_y),\n",
    "    steps_per_epoch = N_TRAIN_DATA//BATCH_SIZE,\n",
    "    epochs = 50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test_x)\n",
    "from IPython.display import display_png\n",
    "for i in range(test_x.shape[0]):\n",
    "    display_png(array_to_img(test_x[i]))\n",
    "    display_png(array_to_img(test_y[i]))\n",
    "    display_png(array_to_img(pred[i]))\n",
    "    print('-'*25)\n",
    "    if i == 2:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
